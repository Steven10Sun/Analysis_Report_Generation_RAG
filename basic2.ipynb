{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "import openai\n",
    "import requests\n",
    "\n",
    "from library.exportation import export_prompt_response, export_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total revenue for the Reporting Period from Continuing Connected Transactions at Issuer Level and Subsidiary Level was HK$6,802.2 million and HK$429.7 million, respectively, accounting for approximately 78.1% and 4.9% of our total revenue, respectively.\n",
      "The total revenue for the Reporting Period from Continuing Connected Transactions at Issuer Level and Subsidiary Level was HK$6,802.2 million and HK$429.7 million, respectively, accounting for approximately 78.1% and 4.9% of our total revenue, respectively.\n"
     ]
    }
   ],
   "source": [
    "# test ollama\n",
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "response: ChatResponse = chat(model='llama3', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': \"\"\"Please follow the format to answer the questions.\n",
    "    give me the answer maxmium to 3 sentense.\n",
    "       \n",
    "    Here is the retrieved context:\n",
    "terms of the connected transactions conducted during the Reporting Period. During the Reporting Period, the aggregate revenue \n",
    "amount of the Continuing Connected Transactions at Issuer Level and the Continuing Connected Transactions at Subsidiary \n",
    "Level was HK$6,802.2 million and HK$429.7 million, respectively, accounting for approximately 78.1% and 4.9% of our total \n",
    "revenue, respectively, during the Reporting Period. The total procurement of the Continuing Connected Transactions at Issuer \n",
    "Level and the Continuing Connected Transactions at Subsidiary Level was HK$1,635.2 million and HK$1,583.3 million, \n",
    "respectively, accounting for approximately 19.0% and 18.4% of our total purchase, respectively, during the Reporting Period.\n",
    "The details of the Continuing Connected Transactions conducted by the Group during the Reporting Period that are subject to \n",
    "reporting requirement under the Listing Rules are set out in this section. Unless otherwise defined herein, capitalised terms used\n",
    "decrease in sales volume was mainly due to that marketable goods were in short supply and could not fully meet customer needs. \n",
    "The increase in revenue while decrease in gross profit are mainly because there have been significant changes in product structure \n",
    "compared with the same period last year, namely, the sales volume of finished tobacco strips with higher unit sale price but lower \n",
    "gross profit level has shown a relatively significant increase in sales proportion, while sales volume of tobacco leaf by-products \n",
    "with higher gross profit level but lower unit sale price has decreased in sales proportion.\n",
    "PROSPECTS FOR THE SECOND HALF OF 2024\n",
    "In the second half of 2024, we will uphold the tenet of “respect market, respect rules, respect investors”, and based on the \n",
    "strategic position of “capital markets operation and international business expansion platform” to achieve the Group’s \n",
    "high-quality development goals by prioritising the following areas in our efforts:\n",
    "Notes:\n",
    "1. In light of the fact that CNTC directly controls one third or more of the voting rights in the shareholders’ meetings of CTIG, in accordance \n",
    "with the SFO, the interests of CTIG are deemed to be, and have therefore been included in, the interests of CNTC.\n",
    "2. As at 30 June 2024, the Company had 691,680,000 Shares in issue.\n",
    "Apart from the foregoing, as at 30 June 2024, no other person (other than a Director or the chief executive of the Company) \n",
    "had any interests or short positions in the Shares and underlying Shares as recorded in the register required to be kept by the \n",
    "Company under section 336 of the SFO, or as otherwise notified to the Company and the Stock Exchange.41\n",
    "Interim Report 2024\n",
    "Other Information (Continued)\n",
    "CHANGES IN DIRECTORS’ BIOGRAPHICAL DETAILS\n",
    "During the annual general meeting of the Company dated 17 May 2024 (the “2024 AGM”), Mr. Dai Jiahui was re-elected as\n",
    "Question: What is the total revenue for the reporting period? \n",
    "Answer: \"\"\",\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])\n",
    "# or access fields directly from the response object\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_text(pdf_path):\n",
    "    \"\"\"Load text from a PDF file.\"\"\"\n",
    "    text = \"\"\n",
    "    with open(pdf_path, \"rb\") as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text() or \"\"\n",
    "    return text\n",
    "\n",
    "def generate_answer(context, question, api_key):\n",
    "    model = 'gpt-4o-mini'\n",
    "    url = \"https://api.ohmygpt.com/v1/chat/completions\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a financial assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Context: {context} Question: {question}\"}\n",
    "        ],\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    response_json = response.json()\n",
    "    return response_json[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "def generate_summary(answers, api_key):\n",
    "    model = 'gpt-4o-mini'\n",
    "    url = \"https://api.ohmygpt.com/v1/chat/completions\"\n",
    "\n",
    "    summary_prompt = f\"\"\"Based on the questions and answers provided. please write a financial report. \\n\\nThe context is as below \\n{answers}\"\"\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a article writer.\"},\n",
    "            {\"role\": \"user\", \"content\": summary_prompt}\n",
    "        ],\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"\"\n",
    "file_name = '6055.HK'\n",
    "folder_name = '3_data'\n",
    "pdf_file_path = os.path.join(folder_name, f'{file_name}.pdf')\n",
    "pdf_text = load_pdf_text(pdf_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt()\n",
    "answers = generate_answer(pdf_text, prompt, api_key)\n",
    "aritcle = generate_summary(answers, api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report has been exported to 2_article_log\\6055.HK_20241122_0016.txt\n"
     ]
    }
   ],
   "source": [
    "export_article(file_name, aritcle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rag_pipeline.py\n",
    "\n",
    "import requests\n",
    "from prompt_template import prompt_template\n",
    "import langchain as lc\n",
    "from langchain.document_loaders import LocalLoader\n",
    "from langchain.retrievers import DenseRetriever\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Initialize document loader\n",
    "loader = LocalLoader(\n",
    "    path=\"path/to/your/documents\",\n",
    "    file_extensions=[\".txt\", \".pdf\", \".docx\"]\n",
    ")\n",
    "\n",
    "# Initialize retriever\n",
    "retriever = DenseRetriever(\n",
    "    loader=loader,\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    ")\n",
    "\n",
    "# Load the pre-trained sentence transformer model\n",
    "embedding_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "def chunk_text(text, chunk_size=512, overlap=50):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = min(start + chunk_size, len(text))\n",
    "        chunks.append(text[start:end])\n",
    "        start += chunk_size - overlap\n",
    "    return chunks\n",
    "\n",
    "def embed_text_chunks(chunks):\n",
    "    embeddings = embedding_model.encode(chunks, convert_to_tensor=True)\n",
    "    return embeddings\n",
    "\n",
    "def get_most_relevant_chunk(question, chunks, embeddings):\n",
    "    question_embedding = embedding_model.encode([question], convert_to_tensor=True)\n",
    "    similarity_scores = cosine_similarity(question_embedding, embeddings)\n",
    "    most_relevant_idx = np.argmax(similarity_scores)\n",
    "    return chunks[most_relevant_idx]\n",
    "\n",
    "def generate_response(context, question, api_key):\n",
    "    model = 'ollama'\n",
    "    url = \"https://api.ollama.ai/v1/chat/completions\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    \n",
    "    prompt = prompt_template.format(context=context, question=question)\n",
    "    \n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    response_json = response.json()\n",
    "    return response_json[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# Main function to load PDF, chunk text, embed chunks, and generate response\n",
    "def main(pdf_path, question, api_key):\n",
    "    # Load text from PDF (assuming a function load_pdf_text is defined)\n",
    "    text = load_pdf_text(pdf_path)\n",
    "    chunks = chunk_text(text)\n",
    "    \n",
    "    chunk_embeddings = embed_text_chunks(chunks)\n",
    "    most_relevant_chunk = get_most_relevant_chunk(question, chunks, chunk_embeddings)\n",
    "    \n",
    "    answer = generate_response(most_relevant_chunk, question, api_key)\n",
    "    print(answer)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_path = \"path/to/your/pdf_file.pdf\"\n",
    "    question = \"What are the recent advancements in AI research?\"\n",
    "    api_key = \"your_api_key\"\n",
    "    \n",
    "    main(pdf_path, question, api_key)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
