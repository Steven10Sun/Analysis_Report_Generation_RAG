{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import torch\n",
    "# import torchvision\n",
    "# import openai\n",
    "import PyPDF2\n",
    "import spacy\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "from library.exportation import export_prompt_response, export_article\n",
    "from get_embedding_function import get_embedding_function\n",
    "from prompt_template import define_company_prompt, ask_question_prompt, write_report_prompt, generate_response\n",
    "from question_bank import question_1, question_3306, question_6055, question_778, question_916\n",
    "key = \"API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_text(pdf_path):\n",
    "    \"\"\"Load text from a PDF file.\"\"\"\n",
    "    text = \"\"\n",
    "    with open(pdf_path, \"rb\") as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text() or \"\"\n",
    "    text = text.replace('\\n', '')\n",
    "    return text\n",
    "\n",
    "\n",
    "def embedding(chunks, nlp):\n",
    "    \"\"\"Encode text chunks using spaCy.\"\"\"\n",
    "    encoded_chunks = []\n",
    "    for chunk in chunks:\n",
    "        doc = nlp(chunk)\n",
    "        encoded_chunks.append(doc.vector)  # Get the vector representation\n",
    "    return encoded_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '916.HK'\n",
    "folder_name = '3_data'\n",
    "pdf_file_path = os.path.join(folder_name, f'{file_name}.pdf')\n",
    "pdf_text = load_pdf_text(pdf_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunking and Embedding for PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True  #add_start_index=True else kernel die\n",
    ")\n",
    "\n",
    "# Split the text into chunks\n",
    "text_chunks = text_splitter.split_text(pdf_text)\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_md\")  # Load the spaCy model\n",
    "\n",
    "# Encode the chunks from pdf\n",
    "encoded_chunks = embedding(text_chunks, nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def define_company_prompt(content):\n",
    "#     system_prompt = f\"\"\"Analyze the following text chunks and identify the company. \n",
    "#     Just provide the company and the stock code only.\n",
    "#     Chunks:\n",
    "#     {content}\n",
    "#     \"\"\"\n",
    "#     return system_prompt\n",
    "\n",
    "\n",
    "# def generate_company_name(prompt, api_key, system_content='you are a assistant'):\n",
    "#     model = 'gpt-4o-mini'\n",
    "#     url = \"https://api.ohmygpt.com/v1/chat/completions\"\n",
    "    \n",
    "#     headers = {\n",
    "#         \"Content-Type\": \"application/json\",\n",
    "#         \"Authorization\": f\"Bearer {api_key}\"\n",
    "#     }\n",
    "    \n",
    "#     data = {\n",
    "#         \"model\": model,\n",
    "#         \"messages\": [\n",
    "#             {\"role\": \"system\", \"content\": system_content},\n",
    "#             {\"role\": \"user\", \"content\": prompt}\n",
    "#         ],\n",
    "#         \"temperature\": 0.7\n",
    "#     }\n",
    "#     response = requests.post(url, headers=headers, json=data)\n",
    "#     response_json = response.json()\n",
    "#     return response_json[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_company_question(company_name):\n",
    "    if 'Tobacco' in company_name or '6055' in company_name:\n",
    "        return question_6055\n",
    "    elif 'Hutchison' in company_name or '1' in company_name:\n",
    "        return question_1\n",
    "    elif 'JNBY' in company_name or '3306' in company_name:\n",
    "        return question_3306\n",
    "    elif 'Fortune REIT' in company_name or '778' in company_name:\n",
    "        return question_778\n",
    "    elif 'Longyua' in company_name or '916' in company_name:\n",
    "        return question_916\n",
    "    else:\n",
    "        stock_code = input('Input the stock code: ')\n",
    "        if stock_code == '6055':\n",
    "            return question_6055\n",
    "        if stock_code == '1':\n",
    "            return question_1\n",
    "        if stock_code == '3306':\n",
    "            return question_3306\n",
    "        if stock_code == '778':\n",
    "            return question_778\n",
    "        if stock_code == '916':\n",
    "            return question_916\n",
    "\n",
    "first_chunk = text_chunks[0]\n",
    "name_prompt = define_company_prompt(first_chunk)\n",
    "company_name = generate_response(name_prompt, key)\n",
    "questions = get_company_question(company_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 5 similar token \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_N = 3\n",
    "top_N_chunks = {}\n",
    "\n",
    "for i, q in enumerate(questions):\n",
    "    q_emb = nlp(q).vector\n",
    "    # Find the most similar chunks to q_emb\n",
    "    similarities = cosine_similarity([q_emb], encoded_chunks).flatten()\n",
    "\n",
    "    top_N_idx = similarities.argsort()[::-1][:top_N]\n",
    "    \n",
    "    top_N_text = [text_chunks[i] for i in top_N_idx]\n",
    "\n",
    "    top_N_chunks[q] = top_N_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ask_question_prompt(content, question):\n",
    "#     system_prompt = f\"\"\"You are an financial analyst.\n",
    "#     Use the following pieces of retrieved context to answer the question. \n",
    "#     Use 3 sentences maximum for question and keep the answer concise.\n",
    "\n",
    "\n",
    "#     Retrieved context:\n",
    "#     {content}\\n\n",
    "\n",
    "#     Question:\n",
    "#     {question}\n",
    "#     \"\"\"\n",
    "#     return system_prompt\n",
    "\n",
    "\n",
    "# def write_report_prompt(content):\n",
    "#     system_prompt = f\"\"\"You are a financial report writer. \n",
    "#     Please combine the text provided and generate a financial analysis report. \n",
    "#     The report should be about 15 to 20 paragraphs. The report should include the following sections:\n",
    "#     1. Company Overview\n",
    "#     2. Revenue Structure\n",
    "#     3. Profit\n",
    "#     4. Valuation\n",
    "#     5. Summary\n",
    "#     6. Future Outlook\n",
    "#     7. and other details provided.\n",
    "    \n",
    "#     content is as below:\n",
    "#     {content}\n",
    "#     \"\"\"\n",
    "#     return system_prompt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def generate_answer(prompt, api_key):\n",
    "#     model = 'gpt-4o-mini'\n",
    "#     url = \"https://api.ohmygpt.com/v1/chat/completions\"\n",
    "    \n",
    "#     headers = {\n",
    "#         \"Content-Type\": \"application/json\",\n",
    "#         \"Authorization\": f\"Bearer {api_key}\"\n",
    "#     }\n",
    "    \n",
    "#     data = {\n",
    "#         \"model\": model,\n",
    "#         \"messages\": [\n",
    "#             {\"role\": \"system\", \"content\": \"You are a financial assistant asking questions.\"},\n",
    "#             {\"role\": \"user\", \"content\": prompt}\n",
    "#         ],\n",
    "#         \"temperature\": 0.7\n",
    "#     }\n",
    "#     response = requests.post(url, headers=headers, json=data)\n",
    "#     response_json = response.json()\n",
    "#     return response_json[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "# def generate_summary(prompt, api_key):\n",
    "#     model = 'gpt-4o-mini'\n",
    "#     url = \"https://api.ohmygpt.com/v1/chat/completions\"\n",
    "    \n",
    "#     headers = {\n",
    "#         \"Content-Type\": \"application/json\",\n",
    "#         \"Authorization\": f\"Bearer {api_key}\"\n",
    "#     }\n",
    "    \n",
    "#     data = {\n",
    "#         \"model\": model,\n",
    "#         \"messages\": [\n",
    "#             {\"role\": \"system\", \"content\": \"You are a writer.\"},\n",
    "#             {\"role\": \"user\", \"content\": prompt}\n",
    "#         ],\n",
    "#         \"temperature\": 0.7\n",
    "#     }\n",
    "#     response = requests.post(url, headers=headers, json=data)\n",
    "#     response_json = response.json()\n",
    "#     return response_json[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt to llm to ask question\n",
    "all_prompts = []\n",
    "\n",
    "# combine chunks and questions to string\n",
    "for question, top_chunks in top_N_chunks.items():\n",
    "    top_chunks_combined = '. '.join(top_chunks)\n",
    "    system_prompt = ask_question_prompt(top_chunks_combined, question)\n",
    "    all_prompts.append((question, system_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 100/100 [06:43<00:00,  4.03s/it]\n"
     ]
    }
   ],
   "source": [
    "prompt_response = []\n",
    "c = 0\n",
    "for i, (q, p) in tqdm(enumerate(all_prompts), \n",
    "                      total=len(all_prompts), \n",
    "                      desc=\"Processing: \"):\n",
    "    response = generate_response(p, key)\n",
    "    prompt_response.append((q, response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data has been exported to 1_prompt_log\\916.HK_20241127_0009.json\n"
     ]
    }
   ],
   "source": [
    "prompt_hist = {}\n",
    "for q, r in  prompt_response:\n",
    "    prompt_hist[q] = r\n",
    "\n",
    "export_prompt_response(file_name, prompt_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report has been exported to 2_report_log\\916.HK_20241127_0013.txt\n"
     ]
    }
   ],
   "source": [
    "content = ''\n",
    "for q, r in prompt_response:\n",
    "    content += f'{q} {r}\\n'\n",
    "summary_prompt = write_report_prompt(content)\n",
    "report = generate_response(summary_prompt, key)\n",
    "\n",
    "export_article(file_name, prompt_hist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
