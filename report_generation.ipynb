{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from openpyxl import load_workbook\n",
    "# import torch\n",
    "# import torchvision\n",
    "# import openai\n",
    "import PyPDF2\n",
    "import spacy\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain.llms import OpenAI\n",
    "from library.exportation import export_prompt_response, export_article\n",
    "\n",
    "from prompt_template import define_company_prompt, ask_question_prompt, write_report_prompt, generate_response\n",
    "# from question_bank import question_1, question_3306, question_6055, question_778, question_916\n",
    "key = \"sk-NAWSSGI7999d18B51046T3BlBkFJ514d034054e342cc99c3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_text(pdf_path):\n",
    "    \"\"\"Load text from a PDF file.\"\"\"\n",
    "    text = \"\"\n",
    "    with open(pdf_path, \"rb\") as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text() or \"\"\n",
    "    text = text.replace('\\n', '')\n",
    "    return text\n",
    "\n",
    "\n",
    "def embedding(chunks, nlp):\n",
    "    \"\"\"Encode text chunks using spaCy.\"\"\"\n",
    "    encoded_chunks = []\n",
    "    for chunk in chunks:\n",
    "        doc = nlp(chunk)\n",
    "        encoded_chunks.append(doc.vector)  # Get the vector representation\n",
    "    return encoded_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = '1.HK'\n",
    "# file_name = '778.HK'\n",
    "# file_name = '916.HK'\n",
    "# file_name = '3306.HK'\n",
    "file_name = '6055.HK'\n",
    "\n",
    "folder_name = '3_data'\n",
    "pdf_file_path = os.path.join(folder_name, f'{file_name}.pdf')\n",
    "pdf_text = load_pdf_text(pdf_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chunking & Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True  #add_start_index=True else kernel die\n",
    ")\n",
    "\n",
    "# Split the text into chunks\n",
    "text_chunks = text_splitter.split_text(pdf_text)\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_md\")  # Load the spaCy model\n",
    "\n",
    "# Encode the chunks from pdf\n",
    "encoded_chunks = embedding(text_chunks, nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company code:  6055\n"
     ]
    }
   ],
   "source": [
    "def get_company_code(company_name):\n",
    "    if 'Tobacco' in company_name or '6055' in company_name:\n",
    "        return '6055'\n",
    "    elif 'JNBY' in company_name or '3306' in company_name:\n",
    "        return '3306'\n",
    "    elif 'Fortune REIT' in company_name or '778' in company_name:\n",
    "        return '778'\n",
    "    elif 'Longyua' in company_name or '916' in company_name:\n",
    "        return '916'\n",
    "    elif 'Hutchison' in company_name or '1' in company_name:\n",
    "        return '1'\n",
    "    else:\n",
    "        return input('Input the stock code: ')\n",
    "\n",
    "first_chunk = text_chunks[0]\n",
    "name_prompt = define_company_prompt(first_chunk)\n",
    "company_name = generate_response(name_prompt, key)\n",
    "company_code = get_company_code(company_name)\n",
    "print('company code: ', company_code)\n",
    "questions = pd.read_excel('questions.xlsx', sheet_name=company_code).iloc[:, -1].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top N similar token \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_N = 3\n",
    "top_N_chunks = {}\n",
    "\n",
    "for i, q in enumerate(questions):\n",
    "    q_emb = nlp(q).vector\n",
    "    # Find the most similar chunks to q_emb\n",
    "    similarities = cosine_similarity([q_emb], encoded_chunks).flatten()\n",
    "\n",
    "    top_N_idx = similarities.argsort()[::-1][:top_N]\n",
    "    \n",
    "    top_N_text = [text_chunks[i] for i in top_N_idx]\n",
    "\n",
    "    top_N_chunks[q] = top_N_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167404"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt to llm to ask question\n",
    "all_prompts = []\n",
    "\n",
    "# combine chunks and questions to string\n",
    "for question, top_chunks in top_N_chunks.items():\n",
    "    top_chunks_combined = '. '.join(top_chunks)\n",
    "    system_prompt = ask_question_prompt(top_chunks_combined, question)\n",
    "    all_prompts.append((question, system_prompt))\n",
    "\n",
    "sum(len(j) for _, j in all_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 50/50 [03:21<00:00,  4.02s/it]\n"
     ]
    }
   ],
   "source": [
    "prompt_response = []\n",
    "c = 0\n",
    "for i, (q, p) in tqdm(enumerate(all_prompts), \n",
    "                      total=len(all_prompts), \n",
    "                      desc=\"Processing: \"):\n",
    "    response = generate_response(p, key)\n",
    "    prompt_response.append((q, response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save version of response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'response.xlsx'\n",
    "version = 'ver2'\n",
    "book = load_workbook(file_path)\n",
    "update_sheet = company_code\n",
    "\n",
    "target_company = pd.read_excel(file_path, sheet_name=update_sheet)\n",
    "target_company[version] = pd.DataFrame(prompt_response).iloc[:, -1]\n",
    "\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    target_company.to_excel(writer, sheet_name=update_sheet, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_list = ['1', '778', '916', '3306', '6055']\n",
    "report_list = []\n",
    "\n",
    "for code in code_list:\n",
    "    content = ''\n",
    "    q = pd.read_excel('questions.xlsx', sheet_name=code).iloc[:, -1].dropna()\n",
    "    r = pd.read_excel('response.xlsx', sheet_name=code).iloc[:, -1].dropna()\n",
    "    for i, j in zip(q, r):\n",
    "        content += i + j + '\\n\\n'\n",
    "    summary_prompt = write_report_prompt(content)\n",
    "    report = generate_response(summary_prompt, key)\n",
    "    report_list.append(pd.DataFrame([report], columns=['ver2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_1, report_778, report_916, report_3306, report_6055 = report_list\n",
    "with pd.ExcelWriter('reports.xlsx') as writer:\n",
    "    report_1.to_excel(writer, sheet_name='1', index=False)\n",
    "    report_778.to_excel(writer, sheet_name='778', index=False)\n",
    "    report_916.to_excel(writer, sheet_name='916', index=False)\n",
    "    report_3306.to_excel(writer, sheet_name='3306', index=False)\n",
    "    report_6055.to_excel(writer, sheet_name='6055', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
