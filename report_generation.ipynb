{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from openpyxl import load_workbook\n",
    "# import torch\n",
    "# import torchvision\n",
    "# import openai\n",
    "import PyPDF2\n",
    "import spacy\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain.llms import OpenAI\n",
    "from library.exportation import export_prompt_response, export_article\n",
    "\n",
    "from prompt_template import (define_company_prompt, \n",
    "                             ask_question_prompt, \n",
    "                             write_report_prompt, \n",
    "                             generate_response, \n",
    "                             company_overview_prompt, \n",
    "                             revenue_structure_prompt, \n",
    "                             profit_prompt, \n",
    "                             valuation_prompt, \n",
    "                             future_outlook_prompt, \n",
    "                             write_sector_prompt)\n",
    "# from question_bank import question_1, question_3306, question_6055, question_778, question_916\n",
    "key = \"sk-NAWSSGI7999d18B51046T3BlBkFJ514d034054e342cc99c3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_text(pdf_path):\n",
    "    \"\"\"Load text from a PDF file.\"\"\"\n",
    "    text = \"\"\n",
    "    with open(pdf_path, \"rb\") as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text() or \"\"\n",
    "    text = text.replace('\\n', '')\n",
    "    return text\n",
    "\n",
    "\n",
    "def embedding(chunks, nlp):\n",
    "    \"\"\"Encode text chunks using spaCy.\"\"\"\n",
    "    encoded_chunks = []\n",
    "    for chunk in chunks:\n",
    "        doc = nlp(chunk)\n",
    "        encoded_chunks.append(doc.vector)  # Get the vector representation\n",
    "    return encoded_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'ver4'\n",
    "# file_name = '1.HK'\n",
    "# file_name = '778.HK'\n",
    "# file_name = '916.HK'\n",
    "file_name = '3306.HK'\n",
    "# file_name = '6055.HK'\n",
    "\n",
    "folder_name = '3_data'\n",
    "pdf_file_path = os.path.join(folder_name, f'{file_name}.pdf')\n",
    "pdf_text = load_pdf_text(pdf_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chunking & Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, chunk_overlap=100, add_start_index=True  #add_start_index=True else kernel die\n",
    ")\n",
    "\n",
    "# Split the text into chunks\n",
    "text_chunks = text_splitter.split_text(pdf_text)\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_md\")  # Load the spaCy model\n",
    "\n",
    "# Encode the chunks from pdf\n",
    "encoded_chunks = embedding(text_chunks, nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This annual r eport is print ed on envir onment al paperCONTENTSCompany Introduction 6Corporate Information 7Financial Summary 8Chairman’s Statement 10Management Discussion and Analysis 11Directors and Senior Management 20Directors’ Report 25Corporate Governance Report 45Environmental, Social and Governance Report 61Independent Auditor’s Report 117Consolidated Statement of Comprehensive Income 121Consolidated Balance Sheet 122Consolidated Statement of Changes in Equity 124Consolidated Statement'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company code:  3306\n"
     ]
    }
   ],
   "source": [
    "def get_company_code(company_name):\n",
    "    if 'Tobacco' in company_name or '6055' in company_name:\n",
    "        return '6055'\n",
    "    elif 'JNBY' in company_name or '3306' in company_name:\n",
    "        return '3306'\n",
    "    elif 'Fortune REIT' in company_name or '778' in company_name:\n",
    "        return '778'\n",
    "    elif 'Longyua' in company_name or '916' in company_name:\n",
    "        return '916'\n",
    "    elif 'Hutchison' in company_name or '1' in company_name:\n",
    "        return '1'\n",
    "    else:\n",
    "        return input('Input the stock code: ')\n",
    "\n",
    "first_chunk = text_chunks[0]\n",
    "name_prompt = define_company_prompt(first_chunk)\n",
    "company_name = generate_response(name_prompt, key)\n",
    "company_code = get_company_code(company_name)\n",
    "print('company code: ', company_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_questions = pd.read_excel('questions.xlsx', sheet_name=company_code)\n",
    "if version not in company_questions.columns:\n",
    "    company_questions[version] = company_questions.iloc[:, -1].dropna()\n",
    "\n",
    "questions = company_questions[version].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top N similar token \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_N = 5\n",
    "top_N_chunks = {}\n",
    "\n",
    "for i, q in enumerate(questions):\n",
    "    q_emb = nlp(q).vector\n",
    "    # Find the most similar chunks to q_emb\n",
    "    similarities = cosine_similarity([q_emb], encoded_chunks).flatten()\n",
    "\n",
    "    top_N_idx = similarities.argsort()[::-1][:top_N]\n",
    "    \n",
    "    top_N_text = [text_chunks[i] for i in top_N_idx]\n",
    "\n",
    "    top_N_chunks[q] = top_N_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141705"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt to llm to ask question\n",
    "all_prompts = []\n",
    "\n",
    "# combine chunks and questions to string\n",
    "for question, top_chunks in top_N_chunks.items():\n",
    "    top_chunks_combined = '. '.join(top_chunks)\n",
    "    system_prompt = ask_question_prompt(top_chunks_combined, question)\n",
    "    all_prompts.append((question, system_prompt))\n",
    "\n",
    "sum(len(j) for _, j in all_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 50/50 [04:01<00:00,  4.83s/it]\n"
     ]
    }
   ],
   "source": [
    "prompt_response = []\n",
    "c = 0\n",
    "for i, (q, p) in tqdm(enumerate(all_prompts), \n",
    "                      total=len(all_prompts), \n",
    "                      desc=\"Processing: \"):\n",
    "    response = generate_response(p, key)\n",
    "    prompt_response.append((q, response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_overview_q = company_overview_prompt(questions.to_list())\n",
    "revenue_structure_q = revenue_structure_prompt(questions.to_list())\n",
    "profit_q = profit_prompt(questions.to_list())\n",
    "valuation_q = valuation_prompt(questions.to_list())\n",
    "future_outlook_q = future_outlook_prompt(questions.to_list())\n",
    "\n",
    "sectors = [company_overview_q, revenue_structure_q, profit_q, valuation_q, future_outlook_q]\n",
    "sector_name = ['company overview', 'revenue structure', 'profit', 'valuation', 'future outlook']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_element = []\n",
    "for s in sectors:\n",
    "    sector_q = generate_response(s, key)\n",
    "    sector_json_q = json.loads(sector_q)\n",
    "\n",
    "    for n, (q, r) in zip(sector_name, prompt_response):\n",
    "        if q in sector_json_q.keys():\n",
    "            sector_json_q[q] = r\n",
    "\n",
    "    sector_para_prompt = write_sector_prompt(sector_json_q, n)\n",
    "    sector_para = generate_response(sector_para_prompt, key)\n",
    "    article_element.append(sector_para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save version of response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'response.xlsx'\n",
    "\n",
    "book = load_workbook(file_path)\n",
    "update_sheet = company_code\n",
    "\n",
    "target_company = pd.read_excel(file_path, sheet_name=update_sheet)\n",
    "target_company[version] = pd.DataFrame(prompt_response).iloc[:, -1]\n",
    "\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    target_company.to_excel(writer, sheet_name=update_sheet, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_prompt = write_report_prompt(article_element)\n",
    "report = generate_response(summary_prompt, key)\n",
    "report_df = pd.DataFrame([report], columns=[version])\n",
    "\n",
    "existing_report = pd.read_excel('reports.xlsx', sheet_name=company_code)\n",
    "update_report = pd.concat([existing_report, report_df], axis=1)\n",
    "\n",
    "\n",
    "with pd.ExcelWriter('reports.xlsx', engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    update_report.to_excel(writer, sheet_name=company_code, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code_list = ['1', '778', '916', '3306', '6055']\n",
    "# report_list = []\n",
    "\n",
    "# for code in tqdm(code_list):\n",
    "#     content = ''\n",
    "#     qust = pd.read_excel('questions.xlsx', sheet_name=code)\n",
    "#     q = qust[version].dropna()\n",
    "#     resp = pd.read_excel('response.xlsx', sheet_name=code)\n",
    "#     r = resp[version].dropna()\n",
    "#     for i, j in zip(q, r):\n",
    "#         content += i + j + '\\n\\n'\n",
    "#     summary_prompt = write_report_prompt(content)\n",
    "#     report = generate_response(summary_prompt, key)\n",
    "#     report_df = pd.DataFrame([report], columns=[version])\n",
    "    \n",
    "#     existing_report = pd.read_excel('reports.xlsx', sheet_name=code)\n",
    "#     update_report = pd.concat([existing_report, report_df], axis=1)\n",
    "\n",
    "\n",
    "#     with pd.ExcelWriter('reports.xlsx', engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "#         update_report.to_excel(writer, sheet_name=code, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
