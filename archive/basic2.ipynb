{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "import openai\n",
    "import requests\n",
    "\n",
    "from library.exportation import export_prompt_response, export_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_text(pdf_path):\n",
    "    \"\"\"Load text from a PDF file.\"\"\"\n",
    "    text = \"\"\n",
    "    with open(pdf_path, \"rb\") as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text() or \"\"\n",
    "    return text\n",
    "\n",
    "def generate_answer(context, question, api_key):\n",
    "    model = 'gpt-4o-mini'\n",
    "    url = \"https://api.ohmygpt.com/v1/chat/completions\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a financial assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Context: {context} Question: {question}\"}\n",
    "        ],\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    response_json = response.json()\n",
    "    return response_json[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "def generate_summary(answers, api_key):\n",
    "    model = 'gpt-4o-mini'\n",
    "    url = \"https://api.ohmygpt.com/v1/chat/completions\"\n",
    "\n",
    "    summary_prompt = f\"\"\"Based on the questions and answers provided. please write a financial report. \\n\\nThe context is as below \\n{answers}\"\"\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a article writer.\"},\n",
    "            {\"role\": \"user\", \"content\": summary_prompt}\n",
    "        ],\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"\"\n",
    "file_name = '6055.HK'\n",
    "folder_name = '3_data'\n",
    "pdf_file_path = os.path.join(folder_name, f'{file_name}.pdf')\n",
    "pdf_text = load_pdf_text(pdf_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt()\n",
    "answers = generate_answer(pdf_text, prompt, api_key)\n",
    "aritcle = generate_summary(answers, api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report has been exported to 2_article_log\\6055.HK_20241122_0016.txt\n"
     ]
    }
   ],
   "source": [
    "export_article(file_name, aritcle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rag_pipeline.py\n",
    "\n",
    "import requests\n",
    "from prompt_template import prompt_template\n",
    "import langchain as lc\n",
    "from langchain.document_loaders import LocalLoader\n",
    "from langchain.retrievers import DenseRetriever\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Initialize document loader\n",
    "loader = LocalLoader(\n",
    "    path=\"path/to/your/documents\",\n",
    "    file_extensions=[\".txt\", \".pdf\", \".docx\"]\n",
    ")\n",
    "\n",
    "# Initialize retriever\n",
    "retriever = DenseRetriever(\n",
    "    loader=loader,\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    ")\n",
    "\n",
    "# Load the pre-trained sentence transformer model\n",
    "embedding_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "def chunk_text(text, chunk_size=512, overlap=50):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = min(start + chunk_size, len(text))\n",
    "        chunks.append(text[start:end])\n",
    "        start += chunk_size - overlap\n",
    "    return chunks\n",
    "\n",
    "def embed_text_chunks(chunks):\n",
    "    embeddings = embedding_model.encode(chunks, convert_to_tensor=True)\n",
    "    return embeddings\n",
    "\n",
    "def get_most_relevant_chunk(question, chunks, embeddings):\n",
    "    question_embedding = embedding_model.encode([question], convert_to_tensor=True)\n",
    "    similarity_scores = cosine_similarity(question_embedding, embeddings)\n",
    "    most_relevant_idx = np.argmax(similarity_scores)\n",
    "    return chunks[most_relevant_idx]\n",
    "\n",
    "def generate_response(context, question, api_key):\n",
    "    model = 'ollama'\n",
    "    url = \"https://api.ollama.ai/v1/chat/completions\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    \n",
    "    prompt = prompt_template.format(context=context, question=question)\n",
    "    \n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    response_json = response.json()\n",
    "    return response_json[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# Main function to load PDF, chunk text, embed chunks, and generate response\n",
    "def main(pdf_path, question, api_key):\n",
    "    # Load text from PDF (assuming a function load_pdf_text is defined)\n",
    "    text = load_pdf_text(pdf_path)\n",
    "    chunks = chunk_text(text)\n",
    "    \n",
    "    chunk_embeddings = embed_text_chunks(chunks)\n",
    "    most_relevant_chunk = get_most_relevant_chunk(question, chunks, chunk_embeddings)\n",
    "    \n",
    "    answer = generate_response(most_relevant_chunk, question, api_key)\n",
    "    print(answer)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_path = \"path/to/your/pdf_file.pdf\"\n",
    "    question = \"What are the recent advancements in AI research?\"\n",
    "    api_key = \"your_api_key\"\n",
    "    \n",
    "    main(pdf_path, question, api_key)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
